<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | MeelGroup</title>
    <link>https://meelgroup.github.io/project/</link>
      <atom:link href="https://meelgroup.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019</copyright><lastBuildDate>Sat, 04 Apr 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://meelgroup.github.io/images/icon_hu1dd832c4da814f17fe02e3737f0ae144_14882_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://meelgroup.github.io/project/</link>
    </image>
    
    <item>
      <title>Manthan</title>
      <link>https://meelgroup.github.io/project/manthan/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/manthan/</guid>
      <description>&lt;p&gt;Boolean functional synthesis is a fundamental problem in computer science with wide-ranging applications and has witnessed a surge of interest resulting in progressively improved techniques over the past decade. Despite intense algorithmic development, a large number of problems remain beyond the reach of the state of the art techniques. Motivated by the progress in machine learning, we propose Manthan, a novel data-driven approach to Boolean functional synthesis. Manthan views functional synthesis as a classification problem, relying on advances in constrained sampling for data generation, and advances in automated reasoning for a novel proof-guided refinement and provable verification.&lt;/p&gt;
&lt;p&gt;Manthan significantly improves upon the current state of the art, solving 356 benchmarks in comparison to 280, which is the most solved by a state of the art technique; thereby, it demonstrate an increase of 76 benchmarks over the current state of the art. Furthermore, Manthan solves 60 benchmarks that none of the current state of the art techniques could solve.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NPAQ</title>
      <link>https://meelgroup.github.io/project/npaq/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/npaq/</guid>
      <description>&lt;p&gt;Neural networks are increasingly employed in safety-critical domains. This has prompted interest in verifying or certifying logically encoded properties of neural networks. Prior work has largely focused on checking existential properties, wherein the goal is to check whether there exists any input that violates a given property of interest. However, neural network training is a stochastic process, and many questions arising in their analysis require probabilistic and quantitative reasoning, i.e., estimating how many inputs satisfy a given property. To this end, our paper proposes a novel and principled framework to quantitative verification of logical properties specified over neural networks. Our framework is the first to provide PAC-style soundness guarantees, in that its quantitative estimates are within a controllable and bounded error from the true count. We instantiate our algorithmic framework by building a prototype tool called NPAQ that enables checking rich properties over binarized neural networks. We show how emerging security analyses can utilize our framework in 3 applications: quantifying robustness to adversarial inputs, efficacy of trojan attacks, and fairness/bias of given neural networks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ApproxMC</title>
      <link>https://meelgroup.github.io/project/approxmc/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/approxmc/</guid>
      <description>&lt;p&gt;ApproxMC is a hashing-based algorithm for approximate discrete integration over finite domains and provides ($\epsilon$,$\delta$) guarantees. This implementation handles the case when the function is implicitely defined by SAT formula. To the best of our knowledge, the current implementation has the best runtime performance among approximate counting algorithms. We are actively improving algorithm as well as implementation and would love to hear your feedback.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CrystalBall</title>
      <link>https://meelgroup.github.io/project/crystalball/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/crystalball/</guid>
      <description>&lt;p&gt;Boolean satisfiability is a fundamental problem in computerscience with a wide range of applications including planning, configurationmanagement, design and verification of software/hardware systems. Modern SAT solvers achieve scalability and ro-bustness with sophisticated heuristics that are challenging to understandand explain. We propose to view modern conflict-driven clause learning (CDCL) solvers as a composition of classifiers and regressors for different tasks such as branching, clause memory management, and restarting. The current version of CrystalBall focuses on deriving a classifier to keep or throw away a learned clause. In a departure from recent machine learning based techniques, CrystalBall employs supervised learning and uses extensive, multi-gigabyte data extracted from runs of a single SAT solver to perform predictive analytics. Read this 
&lt;a href=&#34;https://www.msoos.org/2019/06/crystalball-sat-solving-data-gathering-and-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog post&lt;/a&gt; for more details.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GANAK</title>
      <link>https://meelgroup.github.io/project/ganak/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/ganak/</guid>
      <description>&lt;p&gt;Given a Boolean formula $F$, the problem of  model counting, also referred to as #SAT, seeks to compute the number of solutions of $F$. Model counting is a fundamental problem with a wide variety of applications ranging from planning, quantified information flow to probabilistic reasoning and the like. The modern #SAT solvers tend to be either based on static decomposition, dynamic decomposition, or a hybrid of the two. Despite dynamic decomposition based #SAT solvers sharing much of their architecture with SAT solvers, the core design and heuristics of dynamic decomposition-based #SAT solvers has remained constant for over a decade. In this paper, we revisit the architecture of the state-of-the-art dynamic decomposition-based #SAT tool, sharpSAT, and demonstrate that by introducing a new notion of probabilistic component caching and the usage of universal hashing for exact model counting along with the development of several new heuristics can lead to significant performance improvement over state-of-the-art model-counters. In particular, we develop GANAK, a new scalable probabilistic exact model counter that outperforms state-of-the-art exact and approximate model counters sharpSAT and ApproxMC3 respectively, both in terms of PAR-2 score and the number of instances solved. Furthermore, in our experiments, the model count returned by GANAK was equal to the exact model count for all the benchmarks. Finally, we observe that recently proposed preprocessing techniques for model counting benefit exact model counters while hurting the performance of approximate model counters.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UniGen</title>
      <link>https://meelgroup.github.io/project/unigen/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/unigen/</guid>
      <description>&lt;p&gt;UniGen is a hashing-based algorithm to generate uniform samples subject to given set of constraints. The primary application of UniGen is in random stimuli generation for hardware and software verification. The current version of the tool has been developed over the years and is parallelizable without losing theoretical guarantees.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Barbarik</title>
      <link>https://meelgroup.github.io/project/barbarik/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/barbarik/</guid>
      <description>&lt;p&gt;The divide between the existence of sampling techniques that have strong theoretical guarantees but fail to scale and scalable techniques with weak or no theoretical guarantees mirrors the gap in software engineering between poor scalability of classical program synthesis techniques and billions of programs that are routinely used by practitioners. One bridge connecting the two extremes in the context of software engineering has been program testing. In contrast to testing for deterministic programs, where one trace is sufficient to prove the existence of a bug, in case of samplers one sample is typically not sufficient to prove non-conformity of the sampler to the desired distribution. This makes one wonder whether it is possible to design testing methodology to test whether a sampler under test generates samples close to a given distribution.&lt;/p&gt;
&lt;p&gt;We present, Barbarik, to test whether the distribution generated is ε−close or η−far from the uniform distribution. In contrast to the sampling techniques that require an exponential or sub-exponential number of samples for sampler whose support can be represented by n bits, Barbarik requires only O(1/(η − ε)4) samples.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WAPS</title>
      <link>https://meelgroup.github.io/project/waps/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/waps/</guid>
      <description>&lt;p&gt;Previous work on applying Knowledge compilation has focused on uniform sampling over all the variables. Since the constraints are written in high level languages such as Verilog, the popular CNF encoding schemes as Tseitin encoding introduces additional auxiliary variables. The resulting CNF formulas are not equivalent but equisatisfiable. In particular, for a formula $G$ specified in high level language we obtain a CNF formula F such that $G (X) = \exists Y F(X,Y)$. This makes one wonder if it is possible to extend Knowledge compilation based techniques to sample over a subset of variables. Furthermore, languages such as Verilog allow specification of weights to user-defined constraints, so there is a need to sample according to the posterior distribution. In this paper, we provide affirmative question to the above two questions: We propose KUS that samples over user defined subset of variables from posterior distribution for a given prior distribution defined over product spaces.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bosphorus</title>
      <link>https://meelgroup.github.io/project/bosphorus/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/bosphorus/</guid>
      <description>&lt;p&gt;Algebraic Normal Form (ANF) and Conjunctive Normal Form (CNF) are commonly used to encode problems in Boolean algebra. ANFs are typically solved via Gröbner basis algorithms, often using more memory than is feasible; while CNFs are solved using SAT solvers, which cannot exploit the algebra of polynomials naturally. We propose a paradigm that bridges between ANF and CNF solving techniques: the techniques are applied in an iterative manner to learn facts to augment the original problems. Experiments on over 1,100 benchmarks arising from four different applications domains demonstrate that learnt facts can significantly improve runtime and enable more benchmarks to be solved.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KUS</title>
      <link>https://meelgroup.github.io/project/kus/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/kus/</guid>
      <description>&lt;p&gt;Uniform sampling has drawn diverse applications in programming languages and software engineering, like in constrained-random verification (CRV), constrained-fuzzing and bug synthesis. The effectiveness of these applications depend on the uniformity of test stimuli generated from a given set of constraints. Despite significant progress over the past few years, the performance of the state of the art techniques still falls short of those of heuristic methods employed in the industry which sacrifice either uniformity or scalability when generating stimuli. In this paper, we propose a new approach to the uniform generation that builds on recent progress in knowledge compilation. The primary contribution of this paper is marrying knowledge compilation with uniform sampling: our algorithm, KUS, employs the state-of-the-art knowledge compilers to first compile constraints into d-DNNF form, and then, generates samples by making two passes over the compiled representation. We show that KUS is able to significantly outperform existing state-of-the-art algorithms, SPUR and UniGen2, by up to 3 orders of magnitude in terms of runtime while achieving a geometric speedup of $1.7\times$ and $8.3\times$ over SPUR and UniGen2 respectively. Also, KUS achieves a lower PAR-2 score, around $0.82\times$ that of SPUR and $0.38\times$ that of UniGen2. Furthermore, KUS achieves speedups of up to 3 orders of magnitude for incremental sampling. The distribution generated by KUS is statistically indistinguishable from that generated by an ideal uniform sampler. Moreover, KUS is almost oblivious to the number of samples requested.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MIS</title>
      <link>https://meelgroup.github.io/project/mis/</link>
      <pubDate>Mon, 05 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/mis/</guid>
      <description>&lt;p&gt;MIS computes minimal Independent Support for a given CNF formula. The implementation is based on MIS algorithm proposed in our CP&amp;rsquo;15 paper, which also won the Best Student Paper Award.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SMTApproxMC</title>
      <link>https://meelgroup.github.io/project/smtapproxmc/</link>
      <pubDate>Fri, 12 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/smtapproxmc/</guid>
      <description>&lt;p&gt;SMTApproxMC is an approximate model counter for Bitvector theory. Given a set of constraints and weight function over assignments, WeightGen outputs samples that satisfy constraints according to weight function.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WeightGen</title>
      <link>https://meelgroup.github.io/project/weightgen/</link>
      <pubDate>Sun, 27 Jul 2014 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/weightgen/</guid>
      <description>&lt;p&gt;WeightGen is hashing-based approximate weighted sampling for weighted CNF formulas. Given a set of constraints and weight function over assignments, WeightGen outputs samples that satisfy constraints according to weight function.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WeightMC</title>
      <link>https://meelgroup.github.io/project/weightmc/</link>
      <pubDate>Sun, 27 Jul 2014 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/weightmc/</guid>
      <description>&lt;p&gt;WeightMC is hashing-based algorithm for weighted counting (discrete integration) over Boolean domains. It takes a CNF formula and weight function as inputs and returns weighted count. In contrast to previous attempts to develop weighted counting that rely on use of Optimization oracles, WeightMC only uses feasibility oracle. A simple reworking of this algorithm was used by Belle et al to predicate delays in UK transportation network.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>1-CARD-XOR</title>
      <link>https://meelgroup.github.io/project/1cardxor/</link>
      <pubDate>Fri, 10 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://meelgroup.github.io/project/1cardxor/</guid>
      <description>&lt;p&gt;The runtime performance of modern SAT solvers is deeply connected to the phase transition behavior of CNF formulas. While CNF solving has witnessed significant runtime improvement over the past two decades, the same does not hold for several other classes such as the conjunction of cardinality and XOR constraints, denoted as CARD-XOR formulas. The problem of determining satisfiability of CARDXOR formulas is a fundamental problem with wide variety of applications ranging from discrete integration in the field of artificial intelligence to maximum likelihood decoding in coding theory. The runtime behavior of random CARD-XOR formulas is unexplored in prior work. In this paper, we present the first rigorous empirical study to characterize the runtime behavior of 1-CARD-XOR formulas. We show empirical evidence of a surprising phase-transition that follows a non-linear tradeoff between CARD and XOR constraints.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
